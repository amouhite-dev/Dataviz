{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'create_dir()'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de créé un dossier qui va contenir tout les histogramme \"\"\"\n",
    "\"\"\" function allowing to create a folder which will contain all the histogram \"\"\"\n",
    "def create_dir():\n",
    "    rep = os.path.join(os. getcwd(), \"ALL_HISTOGRAM\")\n",
    "    if(os.path.isdir(rep)):\n",
    "        file = os.listdir(rep)\n",
    "        for f in file:\n",
    "            os.remove(os.path.join(rep, f))\n",
    "    else:\n",
    "        os.mkdir(rep)\n",
    "    return rep\n",
    "\"\"\"create_dir()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def initialization_of_treatment(name_file, name_sheet, name_keyword_for_extract, name_new_file_extract, name_col,\\n                                name_id_to_sort) '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant l'extraction de la donnée exacte à analyser dans le fichier source \"\"\"\n",
    "\"\"\" function allowing the extraction of the exact data to be analyzed in the source file \"\"\"\n",
    "def initialization_of_treatment(name_file, name_sheet, name_keyword_for_extract, name_new_file_extract, name_col,\n",
    "                                name_id_to_sort):\n",
    "    dest_filename = name_file\n",
    "    print(dest_filename)\n",
    "    data_to_extract = pd.read_excel(dest_filename, sheet_name=name_sheet) # read file to give \n",
    "    new_data = data_to_extract[data_to_extract[name_col]==name_keyword_for_extract].sort_values(by=[name_id_to_sort]) # make \n",
    "    if name_sheet == \"Donnees_Sorties\":\n",
    "        data = new_data[[\"Bdsid\",\"Master Id\",\"Client\", \"Operation\",\"Offre\",\"Cdp\",\n",
    "                                  \"Date Debut Dplt\", \"Date Cr Lien BDSID\",\"Date Installation Client\",\n",
    "                                  \"Date Mise En Service\", \"Date Mef\",]] # only column that I want\n",
    "    elif name_sheet == \"Donnees_Stock\":\n",
    "        data = new_data[[\"Bdsid\",\"Master Id\",\"Client\", \"Operation\",\"Offre\",\"Cdp\",\n",
    "                                  \"Date Debut Dplt\", \"Date_Cr_Lien_BDSID\",'Date Installation Client',\n",
    "                                 \"Date Installation Technique\",\"Date Installation Planifiee\",\n",
    "                                 \"Date Mise En Service\"]] # only column that I want\n",
    "    data_to_treat = data[data[\"Operation\"] == \"ACTIVATION\"].sort_values(by=[name_id_to_sort])\n",
    "    data_to_treat.to_excel(name_new_file_extract, sheet_name=name_sheet, index = False) # create new \n",
    "    data_to_treat_no_Nan = data_to_treat.dropna()\n",
    "    return data_to_treat_no_Nan, data_to_treat\n",
    "\"\"\" def initialization_of_treatment(name_file, name_sheet, name_keyword_for_extract, name_new_file_extract, name_col,\n",
    "                                name_id_to_sort) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' days_holyday(year) '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de créé une liste des jours férié avec un type datetime \"\"\"\n",
    "\"\"\" function allowing to create a list of public holidays with a datetime type \"\"\"\n",
    "def days_holyday(year):\n",
    "    list_of_days_holyday = [\"01/01\", \"13/04\", \"01/05\", \"08/05\", \"21/05\", \"14/07\", \"15/08\", \"01/11\", \"11/11\", \"25/12\"]\n",
    "    list_of_day_holyday = []\n",
    "    list_of_month_holyday = []\n",
    "    list_holydays = []\n",
    "    for date in range(len(list_of_days_holyday)):\n",
    "        s = list_of_days_holyday[date].split(\"/\")\n",
    "        list_holydays.append(datetime.datetime(year,\n",
    "                                              int(s[1].replace('0','')),\n",
    "                                              int(s[0].replace('0',''))))\n",
    "        list_holydays[date]= list_holydays[date].date()\n",
    "    return list(list_holydays)\n",
    "\n",
    "\"\"\" days_holyday(year) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nb_weekday_between_two_date(d, end, excluded=(6, 7))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de déterminer le nombre de semaine entre deux dates \"\"\"\n",
    "\"\"\" function to determine the number of weeks between two dates \"\"\"\n",
    "def nb_weekday_between_two_date(d, end, excluded=(6, 7)):\n",
    "    days = []\n",
    "    nb_week = 0\n",
    "    nb_days = 0\n",
    "    insert = True\n",
    "    holydays_date = []\n",
    "    for i in range(d.year,(end.year+1)):\n",
    "        holydays_date = list(set(holydays_date + days_holyday(i)))\n",
    "    if d.date() > end.date():\n",
    "        d , end = end, d\n",
    "    while d.date() <= end.date():\n",
    "        insert = True\n",
    "        #if(pd.isnull(d.date()) == False and pd.isnull(end.date()) == False):\n",
    "        d += datetime.timedelta(days=1)\n",
    "        if (d.isoweekday() not in excluded and d.date() not in holydays_date)and d.date() <= end.date():\n",
    "            days.append(d)\n",
    "        else:\n",
    "            insert = False \n",
    "        if ((len(days)%5) == 0) and insert == True:\n",
    "            nb_week += 1\n",
    "            nb_days +=5\n",
    "                \n",
    "    if(len(days)%5 != 0):\n",
    "        nb_days =(len(days)- nb_days)\n",
    "    else:\n",
    "        nb_days = 0\n",
    "    return nb_week, nb_days\n",
    "\n",
    "\"\"\"nb_weekday_between_two_date(d, end, excluded=(6, 7))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evaluation_date_replace_nan(data_to_treat_no_Nan,name_sheet, offre)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de connaitre approximativement les dates qui pourrait remplacer les cellule vide\"\"\"\n",
    "\"\"\" function allowing to know approximately the dates which could replace empty cells \"\"\"\n",
    "def evaluation_date_replace_nan(data_to_treat_no_Nan,name_sheet, offre):\n",
    "    list_step_to_nan = [\"First Step Nan\", \"Second Step Nan\", \"Third Step Nan\", \"Fourth Step Nan\"]\n",
    "    list_evaluation_to_nan=[]\n",
    "    moy = 0\n",
    "    ecart = 0\n",
    "    dict_to_eval_nan = {\"First Step Nan\":0, \"Second Step Nan\":0, \"Third Step Nan\":0, \"Fourth Step Nan\":0}\n",
    "    all_offre = list(data_to_treat_no_Nan['Offre'])\n",
    "    if(name_sheet == \"Donnees_Stock\"):\n",
    "        del dict_to_eval_nan[\"Fourth Step Nan\"]\n",
    "    for offre in range(len(all_offre)):\n",
    "        if(name_sheet == \"Donnees_Stock\"):\n",
    "            if(pd.isnull(list(data_to_treat_no_Nan[\"Date Installation Technique\"])[offre]) == True):\n",
    "                 list(data_to_treat_no_Nan['Date Installation Client'])[offre] =  list(data_to_treat_no_Nan[\"Date Installation Planifiee\"])[offre]\n",
    "            elif(pd.isnull(list(data_to_treat_no_Nan[\"Date Installation Planifiee\"])[offre]) == True):\n",
    "                 list(data_to_treat_no_Nan['Date Installation Client'])[offre] =  list(data_to_treat_no_Nan[\"Date Installation Technique\"])[offre]\n",
    "            else:\n",
    "                list(data_to_treat_no_Nan['Date Installation Client'])[offre] =  list(data_to_treat_no_Nan[\"Date Installation Planifiee\"])[offre]\n",
    "            \n",
    "            list_of_all_date = [list(data_to_treat_no_Nan['Date Debut Dplt'])[offre], list(data_to_treat_no_Nan['Date_Cr_Lien_BDSID'])[offre],\n",
    "                                   list(data_to_treat_no_Nan['Date Installation Client'])[offre], list(data_to_treat_no_Nan['Date Mise En Service'])[offre]]\n",
    "            dict_to_eval_nan[\"First Step Nan\"] = dict_to_eval_nan[\"First Step Nan\"] + nb_weekday_between_two_date(list(data_to_treat_no_Nan['Date Debut Dplt'])[offre], list(data_to_treat_no_Nan['Date_Cr_Lien_BDSID'])[offre])[0]\n",
    "            dict_to_eval_nan[\"Second Step Nan\"] = dict_to_eval_nan[\"Second Step Nan\"] + nb_weekday_between_two_date(list(data_to_treat_no_Nan['Date_Cr_Lien_BDSID'])[offre], list(data_to_treat_no_Nan['Date Installation Client'])[offre])[0]\n",
    "        else:\n",
    "            list_of_all_date = [list(data_to_treat_no_Nan['Date Debut Dplt'])[offre], list(data_to_treat_no_Nan['Date Cr Lien BDSID'])[offre],\n",
    "                               list(data_to_treat_no_Nan['Date Installation Client'])[offre], list(data_to_treat_no_Nan['Date Mise En Service'])[offre],\n",
    "                               list(data_to_treat_no_Nan['Date Mef'])[offre]]\n",
    "            dict_to_eval_nan[\"First Step Nan\"] = dict_to_eval_nan[\"First Step Nan\"] + nb_weekday_between_two_date(list(data_to_treat_no_Nan['Date Debut Dplt'])[offre], list(data_to_treat_no_Nan['Date Cr Lien BDSID'])[offre])[0]\n",
    "            dict_to_eval_nan[\"Second Step Nan\"] = dict_to_eval_nan[\"Second Step Nan\"] + nb_weekday_between_two_date(list(data_to_treat_no_Nan['Date Cr Lien BDSID'])[offre], list(data_to_treat_no_Nan['Date Installation Client'])[offre])[0]\n",
    "            dict_to_eval_nan[\"Fourth Step Nan\"] = dict_to_eval_nan[\"Fourth Step Nan\"] + nb_weekday_between_two_date(list(data_to_treat_no_Nan['Date Mise En Service'])[offre], list(data_to_treat_no_Nan['Date Mef'])[offre])[0]\n",
    "            \n",
    "        dict_to_eval_nan[\"Third Step Nan\"] = dict_to_eval_nan[\"Third Step Nan\"] + nb_weekday_between_two_date(list(data_to_treat_no_Nan['Date Installation Client'])[offre], list(data_to_treat_no_Nan['Date Mise En Service'])[offre])[0]\n",
    "    \n",
    "    for key,value in dict_to_eval_nan.items():\n",
    "        dict_to_eval_nan[key]=round(value/len(all_offre))\n",
    "    return dict_to_eval_nan\n",
    "        \n",
    "\"\"\"evaluation_date_replace_nan(data_to_treat_no_Nan,name_sheet, offre)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' check_nb_week_use_to_nan(step_at_moment,dico_to_eval_nan) '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de rajouter un nombre de semaine a la date précédante lorsque \n",
    "la cellule est vide \"\"\"\n",
    "\"\"\" function allowing to add a number of weeks to the previous date when the cell is empty \"\"\"\n",
    "def check_nb_week_use_to_nan(step_at_moment,dico_to_eval_nan):\n",
    "    return datetime.timedelta(weeks=dico_to_eval_nan[step_at_moment+\" Nan\"])\n",
    "\n",
    "\"\"\" check_nb_week_use_to_nan(step_at_moment,dico_to_eval_nan) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' calcul_total_week_do_by_cdp(cdp, l_day, dict_time_do) '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de calculer le temps total pour un projet d'un cdp \"\"\"\n",
    "\"\"\" function allowing to calculate the total time for a project of a cdp \"\"\"\n",
    "def calcul_total_week_do_by_cdp(cdp, l_day, dict_time_do):\n",
    "    total_week, total_day = 0, 0\n",
    "    cpt_day = 0\n",
    "    for key, value in dict_time_do.items():\n",
    "        week = 0\n",
    "        week = value\n",
    "        day = l_day[cpt_day]\n",
    "        total_week = total_week + week\n",
    "        if total_day >= 5:\n",
    "            total_week += 1\n",
    "            total_day = total_day - 5\n",
    "        else:\n",
    "            total_day = total_day + day\n",
    "        cpt_day +=1 \n",
    "    return total_week    \n",
    "\n",
    "\"\"\" calcul_total_week_do_by_cdp(cdp, l_day, dict_time_do) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' create_dict_cdp_time_do(name_cdp, name_project, idProject, list_date_to_check, name_sheet,dico_to_eval_nan) '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de créé un dictionnaire contenant le temps pour chaque phase et le\n",
    "    temps totale pour un projets d'un cdp \"\"\"\n",
    "\"\"\" function allowing to create a dictionary containing the time for each phase and the total\n",
    "    time for a cdp projects \"\"\"\n",
    "def create_dict_cdp_time_do(name_cdp, name_project, idProject, list_date_to_check, name_sheet,dico_to_eval_nan):\n",
    "    list_step = [\"First Step\", \"Second Step\", \"Third Step\", \"Fourth Step\", \"Total week\"]\n",
    "    dict_cdp_time_do = {}\n",
    "    dict_step_to_do_cdp = {}\n",
    "    l_day = []\n",
    "    if(name_sheet == \"Donnees_Stock\"):\n",
    "        del list_step[3]       \n",
    "    for i in range(len(list_step)-1):\n",
    "        week_to_add = 0\n",
    "        if(pd.isnull(list_date_to_check[i]) == True and pd.isnull(list_date_to_check[i+1]) == False):\n",
    "            week_to_add = check_nb_week_use_to_nan(list_step[i],dico_to_eval_nan)\n",
    "            list_date_to_check[i] = list_date_to_check[i+1]-week_to_add\n",
    "        elif(pd.isnull(list_date_to_check[i]) == False and pd.isnull(list_date_to_check[i+1]) == True):\n",
    "            week_to_add = check_nb_week_use_to_nan(list_step[i],dico_to_eval_nan)\n",
    "            list_date_to_check[i+1] = list_date_to_check[i]+week_to_add\n",
    "        elif pd.isnull(list_date_to_check[i]) == True and pd.isnull(list_date_to_check[i+1]) == True:\n",
    "            indexNames = data_to_treat[idProject].index\n",
    "            data_to_treat.drop(indexNames , inplace=True)\n",
    "            continue\n",
    "        date1 = str(list_date_to_check[i]).split(' ')[0].split(\"-\")\n",
    "        date2 = str(list_date_to_check[i+1]).split(' ')[0].split(\"-\")\n",
    "\n",
    "        end = datetime.datetime(int(date2[0]),int(date2[1]),int(date2[2]))\n",
    "        deb = datetime.datetime(int(date1[0]),int(date1[1]),int(date1[2]))\n",
    "\n",
    "        dict_step_to_do_cdp[list_step[i]], day = nb_weekday_between_two_date(deb, end)\n",
    "        l_day.append(day)\n",
    "    dict_step_to_do_cdp[list_step[len(list_step)-1]] = calcul_total_week_do_by_cdp(name_cdp, l_day, dict_step_to_do_cdp)\n",
    "    dict_cdp_time_do[name_cdp] = dict_step_to_do_cdp\n",
    "    dict_cdp_time_do['Project'] = name_project\n",
    "    dict_cdp_time_do['IdProject'] = idProject\n",
    "    return dict_cdp_time_do\n",
    "\n",
    "\"\"\" create_dict_cdp_time_do(name_cdp, name_project, idProject, list_date_to_check, name_sheet,dico_to_eval_nan) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nb_graph_create(taille,N=30,n= 30,NB_GRAPH = 1,before = 0):\n",
    "    NB_GRAPH=taille/N\n",
    "    if(NB_GRAPH>int(NB_GRAPH)):\n",
    "        NB_GRAPH=int(NB_GRAPH)+1\n",
    "    if(NB_GRAPH%2==0):\n",
    "        l=NB_GRAPH/2\n",
    "    else:\n",
    "        l=int(NB_GRAPH/2)+1\n",
    "    return NB_GRAPH\n",
    "#check_nb_graph_create(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataviz(x,y,name_xlabel, name_ylabel, titles, name_img, rep, colors='white'):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x, y)\n",
    "    plt.setp(ax.get_xticklabels(),rotation=90, ha=\"right\")\n",
    "    plt.tick_params(axis='x', which='major', labelsize=10, labelcolor=colors)\n",
    "    plt.tick_params(axis='y', which='major', labelsize=10, labelcolor=colors)\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(name_xlabel, size=10,color=colors)\n",
    "    plt.ylabel(name_ylabel, size=10,color=colors)\n",
    "    plt.title(titles, color=colors)\n",
    "    plt.savefig(os.path.join(rep,name_img+\".png\"))\n",
    "#create_dataviz(['a','e','d','q'], [2,4,5,9],\"cdp\",\"Nombre de projets\",\"Chaque cdp avec son nombre de projet\",'figsize_test5.png','white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' dataviz_cdp_and_nbProject(data_to_treat) '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction retournant un dictionnaire contenant chaque cdp avec son nombre de projet total \"\"\"\n",
    "\"\"\" function returning a dictionary containing each cdp with its total number of projects \"\"\"\n",
    "def listCdp_numberProject(data):\n",
    "    list_cdp_sans_doublons = list(set(data['Cdp']))\n",
    "    list_cdp = list(data['Cdp'])\n",
    "    list_project = list(data['Bdsid'])\n",
    "    cpt_project = 0\n",
    "    dict_cdp_and_project = {}\n",
    "    \n",
    "    for c in range(len(list_cdp_sans_doublons)):\n",
    "        cdp = list_cdp_sans_doublons[c]\n",
    "        if(type(cdp) != str):\n",
    "            list_cdp[c] = \"Sans nom\"\n",
    "            cdp = list_cdp[c]\n",
    "        for p in range(len(list_project)):\n",
    "            if(list_cdp[p] == cdp):\n",
    "                cpt_project+=1\n",
    "        dict_cdp_and_project[cdp] = cpt_project\n",
    "        cpt_project = 0\n",
    "    return dict_cdp_and_project     \n",
    "\n",
    "def dataviz_cdp_and_nbProject(data_to_treat, rep):\n",
    "    N=30\n",
    "    n= 30\n",
    "    NB_GRAPH = 1\n",
    "    before = 0\n",
    "    dico = listCdp_numberProject(data_to_treat)\n",
    "    print(dico)\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for key, value in dico.items():\n",
    "        x.append(key)\n",
    "        y.append(value)\n",
    "    taille = len(x)\n",
    "    if(taille>30):\n",
    "        NB_GRAPH = check_nb_graph_create(taille)\n",
    "        for z in range(NB_GRAPH):\n",
    "            list_time_to_do_x = x[before:N]\n",
    "            list_time_to_do_y = y[before:N]\n",
    "            create_dataviz(list_time_to_do_x, list_time_to_do_y,\"cdp\",\"Nombre de projets\",\"Chaque cdp avec son nombre de projet\",'dataviz_cdp_and_nbProject'+str(z+1), rep)\n",
    "            before=N\n",
    "            N+=n\n",
    "    else:\n",
    "        create_dataviz(list_time_to_do_x, list_time_to_do_y,\"cdp\",\"Nombre de projets\",\"Chaque cdp avec son nombre de projet\",'dataviz_cdp_and_nbProject_Graph', rep)\n",
    "            \n",
    "\"\"\" dataviz_cdp_and_nbProject(data_to_treat) \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataviz_Onecdp_Oneproject(dico_date_in_week,name_cdp, name_project, idProject)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de d'afficher une l'histogramme d'un projet d'un cdp \"\"\"\n",
    "\"\"\" function allowing to display a histogram of a cdp project \"\"\"\n",
    "def dataviz_Onecdp_Oneproject(dico_date_in_week,name_cdp, name_project, idProject, rep):\n",
    "    list_step_to_do = []\n",
    "    xl = []\n",
    "    yl = []\n",
    "    list_time_to_do = dico_date_in_week[name_cdp]\n",
    "    for search in list_time_to_do:\n",
    "        if search['IdProject'] == idProject:\n",
    "            xl = list(search[name_cdp].keys())[:len(list_step_to_do)-1]\n",
    "            yl = list(search[name_cdp].values())[:len(list_step_to_do)-1]\n",
    "            break\n",
    "    title = f\"Temps effectuer par étape par le cdp : {name_cdp} pour le projet {name_project} d'id {idProject}\"\n",
    "    create_dataviz(xl,yl,\"Step\", \"Number week\", title, \"dataviz_Onecdp_Oneproject\", rep)\n",
    "\n",
    "\"\"\"dataviz_Onecdp_Oneproject(dico_date_in_week,name_cdp, name_project, idProject)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' dataviz_AllProject_TotalTime_OneCdp(dico_date_in_week,name_cdp) '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de créé l'histogramme du temps total pour chaque projet d'un cdp \"\"\"\n",
    "\"\"\" function allowing to create the histogram of the total time for each project of a cdp \"\"\"\n",
    "def dataviz_AllProject_TotalTime_OneCdp(dico_date_in_week,name_cdp, rep):\n",
    "    N=30\n",
    "    n= 30\n",
    "    NB_GRAPH = 1\n",
    "    list_step_to_do = []\n",
    "    xl = []\n",
    "    yl = []\n",
    "    list_time_to_do = dico_date_in_week[name_cdp]\n",
    "    before = 0\n",
    "    taille = len(list_time_to_do)\n",
    "    if(taille>30):\n",
    "        NB_GRAPH = check_nb_graph_create(taille)\n",
    "        for z in range(NB_GRAPH):\n",
    "            list_time_to_do = dico_date_in_week[name_cdp][before:N]\n",
    "            for search in list_time_to_do:\n",
    "                xl.append(str(search['IdProject']))\n",
    "                # xl.append(str(search['IdProject'])+\"-\"+str(search['Project']))\n",
    "                yl.append(int(search[name_cdp]['Total week']))\n",
    "            create_dataviz(xl,yl,\"Projects\", \"Total time\", \"Temps totale effectuer pour chacun de ces projets par le cdp\", \"dataviz_AllProject_TotalTime_OneCdp_Graphe\"+str(z+1), rep)\n",
    "            xl=[]\n",
    "            yl=[]\n",
    "            before=N\n",
    "            N+=n\n",
    "    else:\n",
    "        create_dataviz(xl,yl,\"Projects\", \"Total time\", \"Temps totale effectuer pour chacun de ces projets par le cdp\", \"dataviz_AllProject_TotalTime_OneCdp_Graphe.png\", rep)\n",
    "                       \n",
    "\"\"\" dataviz_AllProject_TotalTime_OneCdp(dico_date_in_week,name_cdp) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' calculate_TotalTime_AllProject_Avg_OneCdp(dico_date_in_week,name_cdp) '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de calculer le temps total moyen sur tout les projets d'un cdp \"\"\"\n",
    "\"\"\" function allowing to calculate the average total time on all the projects of a cdp \"\"\"\n",
    "def calculate_TotalTime_AllProject_Avg_OneCdp(dico_date_in_week,name_cdp):\n",
    "    moy, somme = 0, 0\n",
    "    list_time_to_do = dico_date_in_week[name_cdp]\n",
    "    if(type(list_time_to_do[-1]) != int):\n",
    "        for search in list_time_to_do:\n",
    "            somme = somme + search[name_cdp]['Total week']\n",
    "        moy = int(int(somme) / int(len(list_time_to_do)))\n",
    "        dico_date_in_week[name_cdp].append(moy)\n",
    "        return moy\n",
    "    else:\n",
    "        return list_time_to_do[-1]\n",
    "    \n",
    "\"\"\" calculate_TotalTime_AllProject_Avg_OneCdp(dico_date_in_week,name_cdp) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' dataviz_AllCdp_AvgTime(dico_date_in_week,list_cdp) '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction affichant l'histogramme entre temps total moyen de tout les projets d'un cdp \n",
    "    par cdp  \"\"\"\n",
    "\"\"\" function displaying the histogram between average total time of all the projects of \n",
    "    a cdp by cdp \"\"\"\n",
    "def dataviz_AllCdp_AvgTime(dico_date_in_week,list_cdp, rep):\n",
    "    N=30\n",
    "    n= 30\n",
    "    NB_GRAPH = 1\n",
    "    before=0\n",
    "    list_step_to_do = []\n",
    "    xl = []\n",
    "    yl = []\n",
    "    xl=list_cdp\n",
    "    for key, value in dico_date_in_week.items():\n",
    "        yl.append(value[-1])\n",
    "    taille = len(xl)\n",
    "    if(taille>30):\n",
    "        NB_GRAPH = check_nb_graph_create(taille)\n",
    "        for z in range(NB_GRAPH):\n",
    "            list_time_to_do_x = xl[before:N]\n",
    "            list_time_to_do_y = yl[before:N]\n",
    "            create_dataviz(list_time_to_do_x, list_time_to_do_y,\"Step\",\"Nb Week\",\"Temps moyen effectuer par chaque cdp pour tout leur projet \",\"dataviz_AllCdp_AvgTime\"+str(z+1),rep)\n",
    "            before=N\n",
    "            N+=n\n",
    "    else:\n",
    "        create_dataviz(list_time_to_do_x, list_time_to_do_y,\"Step\",\"Nb Week\",\"Temps moyen effectuer par chaque cdp pour tout leur projet \",'dataviz_AllCdp_AvgTime_Graphe',rep)\n",
    "            \n",
    "\"\"\" dataviz_AllCdp_AvgTime(dico_date_in_week,list_cdp) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' check_cdp_out_of_limit_AllProject(dict_delay) '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fonction permettant de vérifier en terme de pourcentage sur combien de projet il etait ou pas dans la marge \"\"\"\n",
    "\"\"\" function allowing to check in terms of percentage on how many project it was or not in the margin \"\"\"\n",
    "def check_cdp_out_of_limit_AllProject(dict_delay):\n",
    "    nb_cdp_in_limit = 0\n",
    "    list_cdp_in_limit = []\n",
    "    nb_cdp_out_limit = 0\n",
    "    list_cdp_out_limit = []\n",
    "    nb_cdp_equal_limit = 0\n",
    "    list_cdp_equal_limit = []\n",
    "    for value in range(len(dict_delay)-1):\n",
    "        if dict_delay[value][name_cdp]['Total week'] < 4:\n",
    "            nb_cdp_in_limit +=1\n",
    "            list_cdp_in_limit.append(dict_delay[value]['IdProject'])            \n",
    "        elif dict_delay[value][name_cdp]['Total week'] > 4:\n",
    "            nb_cdp_out_limit +=1\n",
    "            list_cdp_out_limit.append(dict_delay[value]['IdProject'])  \n",
    "        else:\n",
    "            nb_cdp_equal_limit +=1\n",
    "            list_cdp_equal_limit.append(key) \n",
    "    percent_in_limit = round((nb_cdp_in_limit*100)/len(dict_delay))\n",
    "    percent_out_limit = round((nb_cdp_out_limit*100)/len(dict_delay))\n",
    "    percent_equal_limit = round((nb_cdp_equal_limit*100)/len(dict_delay))\n",
    "    return [percent_in_limit, percent_equal_limit, percent_out_limit], list_cdp_in_limit, list_cdp_out_limit,list_cdp_equal_limit\n",
    "\n",
    "\"\"\" check_cdp_out_of_limit_AllProject(dict_delay) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataviz_check_OneCdp_out_limit_All_Project(list_delay)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" histogramme represente le pourcentage en terme de marge respecter \"\"\"\n",
    "\"\"\" histogram represents the percentage in terms of margin to respect \"\"\"\n",
    "def dataviz_check_OneCdp_out_limit_All_Project(list_delay, rep):\n",
    "    l = [\"IN Limit\", \"Equal Limt\", \"Out Limit\"]\n",
    "    create_dataviz(l, list_delay[0],\"Type de limit\",\"Pourcentage de projet\",\"f'Representation du pourcentage de projet hors limite de date'\",'dataviz_check_OneCdp_out_limit_All_Project', rep)\n",
    "\"\"\"dataviz_check_OneCdp_out_limit_All_Project(list_delay)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc_to_treat\\Suivi_PRI.xlsx\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': # It's the main\n",
    "    rep = create_dir()\n",
    "    \n",
    "    config = pd.read_excel('ConfigExtraction.xlsx')\n",
    "    dict_all_var = dict(zip(config[\"variables\"].to_list(),config[\"values\"].to_list()))\n",
    "    name_dir = dict_all_var[\"dir_parent_name_to_treat\"]\n",
    "    name_file = name_dir+\"\\\\\"+dict_all_var[\"name_file\"]\n",
    "    name_sheet = dict_all_var[\"name_sheet\"]\n",
    "    name_keyword_for_extract = dict_all_var[\"name_keyword_for_extract\"]\n",
    "    name_cdp=dict_all_var[\"name_cdp_study\"]\n",
    "    name_project = dict_all_var[\"name_project_of_cdp\"]\n",
    "    idProject = dict_all_var[\"id_project\"]\n",
    "    name_col_offre = \"Offre\"\n",
    "    name_id_to_sort = 'Bdsid'\n",
    "    name_new_file_extract = name_dir+\"\\\\\"+\"New_\"+name_file.replace(name_dir+\"\\\\\",\"\")\n",
    "    \n",
    "    data_to_extract = pd.read_excel(name_file, sheet_name=name_sheet)\n",
    "    \n",
    "    dict_to_eval_date_nan={}\n",
    "    data_to_treat_no_Nan, data_to_treat = initialization_of_treatment(name_file, name_sheet, name_keyword_for_extract,\n",
    "                                name_new_file_extract, name_col_offre,name_id_to_sort)\n",
    "    \n",
    "    if(len(data_to_treat_no_Nan) == 0):\n",
    "        print(f\"Les données présents sont insuffisants pour l'étude de l'offre {name_keyword_for_extract}\")\n",
    "    else:        \n",
    "        dict_to_eval_date_nan = evaluation_date_replace_nan(data_to_treat_no_Nan,name_sheet, name_col_offre)\n",
    "        all_cdp = list(data_to_treat['Cdp'])\n",
    "        all_project = list(data_to_treat['Client'])\n",
    "        all_Idproject = list(data_to_treat['Bdsid'])\n",
    "        list_action_cdp = []\n",
    "        dict_all_cdp_time_do={}\n",
    "        list_action_every_cdp = []\n",
    "        list_cdp_without_duplication=[]\n",
    "\n",
    "        for cdp in range(len(all_cdp)):\n",
    "            if(name_sheet == \"Donnees_Stock\"):\n",
    "                list_of_all_date = [list(data_to_treat['Date Debut Dplt'])[cdp], list(data_to_treat['Date_Cr_Lien_BDSID'])[cdp],\n",
    "                                       list(data_to_treat['Date Installation Client'])[cdp], list(data_to_treat['Date Mise En Service'])[cdp]]\n",
    "            else:\n",
    "                list_of_all_date = [list(data_to_treat['Date Debut Dplt'])[cdp], list(data_to_treat['Date Cr Lien BDSID'])[cdp],\n",
    "                                   list(data_to_treat['Date Installation Client'])[cdp], list(data_to_treat['Date Mise En Service'])[cdp],\n",
    "                                   list(data_to_treat['Date Mef'])[cdp]]\n",
    "            if(type(all_cdp[cdp]) != str):\n",
    "                all_cdp[cdp] = \"Sans nom\"\n",
    "            list_action_cdp.append(create_dict_cdp_time_do(all_cdp[cdp], all_project[cdp], all_Idproject[cdp], list_of_all_date, name_sheet, dict_to_eval_date_nan))\n",
    "\n",
    "        list_cdp_without_duplication = list(set(all_cdp))\n",
    "        for cdp in list_cdp_without_duplication :\n",
    "            for act_cdp in list_action_cdp:\n",
    "                if cdp == list(act_cdp.keys())[0]:\n",
    "                    list_action_every_cdp.append(act_cdp)\n",
    "                    dict_all_cdp_time_do[cdp] = list_action_every_cdp\n",
    "            list_action_every_cdp=[]\n",
    "            \n",
    "        print(dict_all_cdp_time_do)\n",
    "        \n",
    "        dataviz_cdp_and_nbProject(data_to_treat, rep)\n",
    "        \n",
    "        dataviz_Onecdp_Oneproject(dict_all_cdp_time_do,name_cdp, name_project, idProject, rep)\n",
    "        \n",
    "        dataviz_AllProject_TotalTime_OneCdp(dict_all_cdp_time_do,name_cdp, rep)\n",
    "        \n",
    "        for key, value in dict_all_cdp_time_do.items():\n",
    "            calculate_TotalTime_AllProject_Avg_OneCdp(dict_all_cdp_time_do,key)\n",
    "        dataviz_AllCdp_AvgTime(dict_all_cdp_time_do,list_cdp_without_duplication, rep)\n",
    "        \n",
    "        list_out_bounds = check_cdp_out_of_limit_AllProject(dict_all_cdp_time_do[name_cdp])\n",
    "        dataviz_check_OneCdp_out_limit_All_Project(list_out_bounds, rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
